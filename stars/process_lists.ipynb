{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4df6e-e52e-43b3-a6cc-09aec276cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_IN = 'adapt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba961f61-a2c7-4a29-be23-1c3a20e93ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, re, json, subprocess, sys\n",
    "import importlib.util as il\n",
    "\n",
    "if None in [il.find_spec('python-ulid'), il.find_spec('pyperclip'), il.find_spec('pandas')]:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'python-ulid']);\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyperclip']);\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas']);\n",
    "    \n",
    "from ulid import ULID\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "\n",
    "def gen_ulid():\n",
    "    return str(ULID.from_timestamp(time.time()))\n",
    "\n",
    "def convert_coord(c):\n",
    "    c = str(c)\n",
    "    j = len(c) - 6\n",
    "    d = int(c[0:2 + j])\n",
    "    m = int(c[2 + j:4 + j])\n",
    "    s = float(c[4 + j:6 + j] + '.' + c[6 + j:])\n",
    "    q = 1 if j == 0 else -1\n",
    "    coord = round(q * (d + m / 60 + s / 3600), 6)\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def pprint(dict):\n",
    "    print(json.dumps(dict, indent=2))\n",
    "\n",
    "def comma_followed_by_number(s):\n",
    "    for i, char in enumerate(s[:-1]):\n",
    "        if char == ',' and s[i+1].isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_table_section_from_file(section_header, filename, offset=0):\n",
    "    offset *= 3\n",
    "    section_header = '******* ' + section_header + ' *******'\n",
    "\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    with open(os.path.join(downloads_folder, filename), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    extracted_lines = []\n",
    "    inside_section = False\n",
    "    end_marker_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if section_header in line:\n",
    "            inside_section = True\n",
    "            extracted_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        if inside_section:\n",
    "            if end_marker_count > offset:\n",
    "                extracted_lines.append(line)\n",
    "            # Count lines that are mostly dashes\n",
    "            if line.strip().startswith('---'):\n",
    "                end_marker_count += 1\n",
    "                if end_marker_count >= 3 + offset:\n",
    "                    break\n",
    "\n",
    "    return \"\".join(extracted_lines)\n",
    "\n",
    "def remove_dash_lines(text):\n",
    "    cleaned_lines = [\n",
    "        line for line in text.splitlines()\n",
    "        if not line.strip().startswith(\"---\")\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def convert_pipe_text_to_csv(multi_line_text):\n",
    "    csv_lines = []\n",
    "    for line in multi_line_text.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        \n",
    "        fields = [field.strip() for field in line.strip('|').split('|')]\n",
    "        csv_line = '|'.join(fields)\n",
    "        csv_lines.append(csv_line)\n",
    "\n",
    "    return '\\n'.join(csv_lines)\n",
    "\n",
    "def csv_text_to_dataframe(csv_text):\n",
    "    lines = [line.strip() for line in csv_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    headers = [h.strip() for h in lines[0].split('|')]\n",
    "    \n",
    "    data = []\n",
    "    for line in lines[1:]:\n",
    "        fields = [f.strip() for f in line.split('|')]\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "def read_adaptation_section(section_header, filename, offset=0):\n",
    "    text = extract_table_section_from_file(section_header, filename, offset)\n",
    "    text = remove_dash_lines(text)\n",
    "    text = convert_pipe_text_to_csv(text)\n",
    "    \n",
    "    return csv_text_to_dataframe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba79b7-32d3-40c2-a4e7-07844ede24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = FILE_IN\n",
    "send = read_adaptation_section('SENDING_FP_TCP', filename)\n",
    "rec = read_adaptation_section('FLIGHT_PLAN_TCP', filename)\n",
    "crd = read_adaptation_section('FLIGHT_PLAN_CRDMSG', filename)\n",
    "tt1 = read_adaptation_section('TCW_TDW_LISTS', filename)\n",
    "tt2 = read_adaptation_section('TCW_TDW_LISTS', filename, offset=1)\n",
    "\n",
    "full_file = []\n",
    "downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "with open(os.path.join(downloads_folder, filename), \"r\") as file:\n",
    "    full_file = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892e7ee-6975-46ee-8bcf-4170689b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "counter = 0\n",
    "for c in send['Channel'].unique():\n",
    "    e = {}\n",
    "\n",
    "    i = int(tt2.loc[tt2['Coord. Channel'] == c, '#.'].iloc[0])\n",
    "    e['list_index'] = i\n",
    "    t1 = tt1[tt1['#.'] == str(i)].iloc[0]\n",
    "    t2 = tt2[tt2['#.'] == str(i)].iloc[0]\n",
    "    c0 = crd[crd['Channel'] == c].iloc[0]\n",
    "    \n",
    "    e['id'] = t1['List ID']\n",
    "    e['title'] = t1['Title'].replace('.      ', '')\n",
    "    e['showTitle'] = t1['Show Title']\n",
    "    e['numberOfEntries'] = t1['Number Entries']\n",
    "    e['persistentEntries'] = t1['Prstnt Entries'] == 'Y'\n",
    "    e['showMore'] = t1['More NN/MM'] == 'Y'\n",
    "\n",
    "    cc = {}\n",
    "    cc['id'] = gen_ulid()\n",
    "    cc['flightType'] = 'Departure'\n",
    "\n",
    "    sending_tcps = []\n",
    "    for tcp in send[send['Channel'] == c]['Sending TCPs'].tolist():\n",
    "        sending_tcps.append({'subset': tcp[0], 'sectorId': tcp[1]})\n",
    "    cc['sendingTcps'] = sending_tcps\n",
    "\n",
    "    receiving_tcps = []\n",
    "    for index, row in rec[rec['Channel'] == c].iterrows():\n",
    "        receiver = {}\n",
    "        tcp = row['Receiving TCP']\n",
    "        receiver['receivingTcp'] = {'subset': tcp[0], 'sectorId': tcp[1]}\n",
    "        receiver['autoAcknowledge'] = row['Auto. Ack.'] == 'Y'\n",
    "        receiving_tcps.append(receiver)\n",
    "    cc['receivers'] = receiving_tcps\n",
    " \n",
    "    e['coordinationChannel'] = cc\n",
    "    e['showLineNumbers']  = t2['Line Numbers'] == 'Y'\n",
    "    sortFieldDict = {'ACID': 'AircraftId', 'DZ Entry': 'DZEntry', '': 'None', \\\n",
    "                     'Coord Seq': 'CoordinationSequence', 'Coord Time': 'CoordinationTime'}\n",
    "    e['sortField'] = sortFieldDict[t2['Prim Sort Field']]\n",
    "    e['sortIsAscending'] = t2['Prim Sort Dir'] == 'A'\n",
    "    \n",
    "    # flight_rules = ['ALL', 'IFR', 'VFR', 'OTP', 'IFR/OTP', 'VFR/OTP']\n",
    "    # e['flight_rules'] = flight_rules[int('0' + c0['Flight Rules'])]\n",
    "    # e['adaptation_name'] = ''\n",
    "    # for line in full_file:\n",
    "    #     if '; ' + e['id'] in line:\n",
    "    #         e['adaptation_name'] = line.split(' ')[0].replace('\\t', '')\n",
    "    #         break\n",
    "\n",
    "    data.append(e)\n",
    "\n",
    "    if counter == 0:\n",
    "        pprint(e)\n",
    "        counter += 1\n",
    "\n",
    "downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "out_name = filename.replace('.txt', '') + '_lists.json'\n",
    "with open(os.path.join(downloads_folder, out_name), \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
