{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba961f61-a2c7-4a29-be23-1c3a20e93ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, re, json, subprocess, sys\n",
    "import importlib.util as il\n",
    "\n",
    "if None in [il.find_spec('python-ulid'), il.find_spec('pyperclip'), il.find_spec('pandas')]:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'python-ulid']);\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyperclip']);\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas']);\n",
    "    \n",
    "from ulid import ULID\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "\n",
    "def gen_ulid():\n",
    "    return str(ULID.from_timestamp(time.time()))\n",
    "\n",
    "def convert_coord(c):\n",
    "    c = str(c)\n",
    "    j = len(c) - 6\n",
    "    d = int(c[0:2 + j])\n",
    "    m = int(c[2 + j:4 + j])\n",
    "    s = float(c[4 + j:6 + j] + '.' + c[6 + j:])\n",
    "    q = 1 if j == 0 else -1\n",
    "    coord = round(q * (d + m / 60 + s / 3600), 6)\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def pprint(dict):\n",
    "    print(json.dumps(dict, indent=2))\n",
    "\n",
    "def comma_followed_by_number(s):\n",
    "    for i, char in enumerate(s[:-1]):\n",
    "        if char == ',' and s[i+1].isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_table_section_from_file(section_header, filename, offset=0):\n",
    "    offset *= 3\n",
    "    section_header = '******* ' + section_header + ' *******'\n",
    "\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    with open(os.path.join(downloads_folder, filename), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    extracted_lines = []\n",
    "    inside_section = False\n",
    "    end_marker_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if section_header in line:\n",
    "            inside_section = True\n",
    "            extracted_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        if inside_section:\n",
    "            if end_marker_count > offset:\n",
    "                extracted_lines.append(line)\n",
    "            # Count lines that are mostly dashes\n",
    "            if line.strip().startswith('---'):\n",
    "                end_marker_count += 1\n",
    "                if end_marker_count >= 3 + offset:\n",
    "                    break\n",
    "\n",
    "    return \"\".join(extracted_lines)\n",
    "\n",
    "def remove_dash_lines(text):\n",
    "    cleaned_lines = [\n",
    "        line for line in text.splitlines()\n",
    "        if not line.strip().startswith(\"---\")\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def convert_pipe_text_to_csv(multi_line_text):\n",
    "    csv_lines = []\n",
    "    for line in multi_line_text.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        \n",
    "        fields = [field.strip() for field in line.strip('|').split('|')]\n",
    "        csv_line = '|'.join(fields)\n",
    "        csv_lines.append(csv_line)\n",
    "\n",
    "    return '\\n'.join(csv_lines)\n",
    "\n",
    "def csv_text_to_dataframe(csv_text):\n",
    "    lines = [line.strip() for line in csv_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    headers = [h.strip() for h in lines[0].split('|')]\n",
    "    \n",
    "    data = []\n",
    "    for line in lines[1:]:\n",
    "        fields = [f.strip() for f in line.split('|')]\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "def read_adaptation_section(section_header, filename, offset=0):\n",
    "    text = extract_table_section_from_file(section_header, filename, offset)\n",
    "    text = remove_dash_lines(text)\n",
    "    text = convert_pipe_text_to_csv(text)\n",
    "    \n",
    "    return csv_text_to_dataframe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003c53e-5248-4b23-9895-458fb5793848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scratchpads(rpcs, filename):\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    with open(os.path.join(downloads_folder, filename), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    scratchpads = {}\n",
    "    for idx, row in rpcs.iterrows():\n",
    "        apt = row['Airport ID']\n",
    "        rid = row['RPC ID']\n",
    "\n",
    "        start_breaking = False\n",
    "        search_text = ''\n",
    "        for i in range(0, len(lines)):\n",
    "            if 'RPC_' + apt + '_' + rid + ' MAIN_RWY' in lines[i]:\n",
    "                start_breaking = True\n",
    "                search_text += lines[i] + '\\n'\n",
    "                continue\n",
    "            \n",
    "            if start_breaking:\n",
    "                search_text += lines[i]\n",
    "                if not('equal' in lines[i] or len(lines[i]) <= 1 or \\\n",
    "                    ';' in lines[i][0:int(len(lines[i]) / 2)]) or 'GHOST' in lines[i]:\n",
    "                    break\n",
    "\n",
    "        sp = re.findall(r'equal\\s+scratch\\s+\"(.*?)\"', search_text)\n",
    "        scratchpads[apt + '_' + rid + '_M'] = sp\n",
    "\n",
    "    for idx, row in rpcs.iterrows():\n",
    "        apt = row['Airport ID']\n",
    "        rid = row['RPC ID']\n",
    "\n",
    "        start_breaking = False\n",
    "        search_text = ''\n",
    "        for i in range(0, len(lines)):\n",
    "            if 'RPC_' + apt + '_' + rid + ' ALT_RWY' in lines[i]:\n",
    "                start_breaking = True\n",
    "                search_text += lines[i] + '\\n'\n",
    "                continue\n",
    "            \n",
    "            if start_breaking:\n",
    "                search_text += lines[i]\n",
    "                if not('equal' in lines[i] or len(lines[i]) <= 1 or \\\n",
    "                    ';' in lines[i][0:int(len(lines[i]) / 2)]) or 'GHOST' in lines[i]:\n",
    "                    break\n",
    "\n",
    "        sp = re.findall(r'equal\\s+scratch\\s+\"(.*?)\"', search_text)\n",
    "        scratchpads[apt + '_' + rid + '_A'] = sp\n",
    "\n",
    "    return scratchpads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba79b7-32d3-40c2-a4e7-07844ede24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adapt.txt'\n",
    "rpc0 = read_adaptation_section('RWY_PAIR_CONFIG', filename)\n",
    "rwy1 = read_adaptation_section('RPC_RUNWAY', filename, offset=0)\n",
    "rwy2 = read_adaptation_section('RPC_RUNWAY', filename, offset=1)\n",
    "rwy3 = read_adaptation_section('RPC_RUNWAY', filename, offset=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892e7ee-6975-46ee-8bcf-4170689b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpcs = []\n",
    "scratchpads = find_scratchpads(rpc0, filename)\n",
    "\n",
    "counter = 1\n",
    "for index, row in rpc0.iterrows():\n",
    "    a = {}\n",
    "    rid = row['RPC ID']\n",
    "    \n",
    "    a['id'] = gen_ulid()\n",
    "    a['index'] = counter\n",
    "    a['airportId'] = row['Airport ID']\n",
    "\n",
    "    a['positionSymbolStagger'], a['positionSymbolTie'] = '!', '!'\n",
    "    if len(row['Stagger Mode']) > 0:\n",
    "        a['positionSymbolStagger'] = row['Stagger Mode']\n",
    "    if len(row['Tie Mode']) > 0:\n",
    "        a['positionSymbolTie'] = row['Tie Mode']\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        r_type = 'M'\n",
    "        if i == 1:\n",
    "            r_type = 'S'\n",
    "        \n",
    "        r = {}\n",
    "        d1 = rwy1[(rwy1['Airport ID'] == row['Airport ID']) & \n",
    "            (rwy1['RPC ID'] == rid) & (rwy1['rwy_type'] == r_type)].iloc[0]\n",
    "        rpc_num = d1['#.']\n",
    "        d2 = rwy2[rwy2['#.'] == rpc_num].iloc[0]\n",
    "        d3 = rwy3[rwy3['#.'] == rpc_num].iloc[0]\n",
    "        \n",
    "        r['runwayId'] = d1['Runway ID']\n",
    "        r['headingTolerance'] = int(d1['Heading Tol'])\n",
    "        \n",
    "        r['nearSideHalfWidth'] = float('0' + d3['NS HW'])\n",
    "        if r['nearSideHalfWidth'] < 0.01:\n",
    "            r['nearSideHalfWidth'] = 0.01\n",
    "        \n",
    "        r['farSideHalfWidth'] = float('0' + d3['FS HW'])\n",
    "        if r['farSideHalfWidth'] < 0.01:\n",
    "            r['farSideHalfWidth'] = 0.01\n",
    "        \n",
    "        r['nearSideDistance'] = float('0' + d3['NS Dist'])\n",
    "        if r['nearSideDistance'] < 0.01:\n",
    "            r['nearSideDistance'] = 0.01\n",
    "        \n",
    "        r['regionLength'] = float('0' + d3['Region Len'])\n",
    "        if r['regionLength'] < 0.01:\n",
    "            r['regionLength'] = 0.01\n",
    "            \n",
    "        r['targetReferencePoint'] = {'lat': convert_coord(d1['Tgt Lat']), 'lon': convert_coord(d1['Tgt Long'])}\n",
    "        r['targetReferenceLineHeading'] = float('0' + d2['Tgt Angle'])\n",
    "        r['targetReferenceLineLength'] = int('0' + d2['Tgt Length'])\n",
    "        r['targetReferencePointAltitude'] = int('0' + d2['Tgt Alt'])\n",
    "        r['imageReferencePoint'] = {'lat': convert_coord(d1['Img Lat']), 'lon': convert_coord(d2['Img Long'])}\n",
    "        r['imageReferenceLineHeading'] = float('0' + d2['Img Angle'])\n",
    "        r['imageReferenceLineLength'] = int('0' + d2['Img Length'])\n",
    "        \n",
    "        r['tieModeOffset'] = float('0' + d2['Tie Offset'])\n",
    "        if r['tieModeOffset'] < 0.01:\n",
    "            r['tieModeOffset'] = 0.01\n",
    "            \n",
    "        r['descentPointDistance'] = float('0' + d2['Descent Dist'])\n",
    "        if r['descentPointDistance'] < 0.01:\n",
    "            r['descentPointDistance'] = 0.01\n",
    "            \n",
    "        r['descentPointAltitude'] = int('0' + d3['Descent Alt'])\n",
    "        r['abovePathTolerance'] = int(d3['Above Tol'])\n",
    "        if r['abovePathTolerance'] > 99:\n",
    "            r['abovePathTolerance'] = 99\n",
    "            \n",
    "        r['belowPathTolerance'] = int(d3['Below Tol'])\n",
    "        if r['belowPathTolerance'] > 99:\n",
    "            r['belowPathTolerance'] = 99\n",
    "            \n",
    "        r['defaultLeaderDirection'] = str(d1['Orientation'])\n",
    "        r['scratchpadPatterns'] = []\n",
    "\n",
    "        rpc_scratch_name = a['airportId'] + '_' + rwy1['RPC ID'][0] + '_' + r_type.replace('S', 'A')\n",
    "        if rpc_scratch_name in scratchpads:\n",
    "            r['scratchpadPatterns'] = scratchpads[rpc_scratch_name]\n",
    "\n",
    "        if i == 0:\n",
    "            a['masterRunway'] = r\n",
    "        else:\n",
    "            a['slaveRunway'] = r\n",
    "\n",
    "    rpcs.append(a)\n",
    "\n",
    "    if counter == 1:\n",
    "        pprint(a)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "out_name = (rpc0['Airport ID'].mode()[0]).lower() + '_rpcs.json'\n",
    "with open(os.path.join(downloads_folder, out_name), \"w\") as file:\n",
    "    json.dump(rpcs, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
